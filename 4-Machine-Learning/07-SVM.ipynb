{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 SVM (support vector machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．支持向量机最简单的情况是线性可分支持向量机，或硬间隔支持向量机。构建它的条件是训练数据线性可分。其学习策略是最大间隔法。可以表示为凸二次规划问题，其原始最优化问题为\n",
    "\n",
    "$$\\min _{w, b} \\frac{1}{2}\\|w\\|^{2}$$\n",
    "\n",
    "$$s.t. \\quad y_{i}\\left(w \\cdot x_{i}+b\\right)-1 \\geqslant 0, \\quad i=1,2, \\cdots, N$$\n",
    "\n",
    "求得最优化问题的解为$w^*$，$b^*$，得到线性可分支持向量机，分离超平面是\n",
    "\n",
    "$$w^{*} \\cdot x+b^{*}=0$$\n",
    "\n",
    "分类决策函数是\n",
    "\n",
    "$$f(x)=\\operatorname{sign}\\left(w^{*} \\cdot x+b^{*}\\right)$$\n",
    "\n",
    "最大间隔法中，函数间隔与几何间隔是重要的概念。\n",
    "\n",
    "线性可分支持向量机的最优解存在且唯一。位于间隔边界上的实例点为支持向量。最优分离超平面由支持向量完全决定。\n",
    "二次规划问题的对偶问题是\n",
    "$$\\min \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_{i} \\alpha_{j} y_{i} y_{j}\\left(x_{i} \\cdot x_{j}\\right)-\\sum_{i=1}^{N} \\alpha_{i}$$\n",
    "\n",
    "$$s.t. \\quad \\sum_{i=1}^{N} \\alpha_{i} y_{i}=0$$\n",
    "\n",
    "$$\\alpha_{i} \\geqslant 0, \\quad i=1,2, \\cdots, N$$\n",
    "\n",
    "通常，通过求解对偶问题学习线性可分支持向量机，即首先求解对偶问题的最优值\n",
    " \n",
    "$a^*$，然后求最优值$w^*$和$b^*$，得出分离超平面和分类决策函数。\n",
    "\n",
    "2．现实中训练数据是线性可分的情形较少，训练数据往往是近似线性可分的，这时使用线性支持向量机，或软间隔支持向量机。线性支持向量机是最基本的支持向量机。\n",
    "\n",
    "对于噪声或例外，通过引入松弛变量$\\xi_{\\mathrm{i}}$，使其“可分”，得到线性支持向量机学习的凸二次规划问题，其原始最优化问题是\n",
    "\n",
    "$$\\min _{w, b, \\xi} \\frac{1}{2}\\|w\\|^{2}+C \\sum_{i=1}^{N} \\xi_{i}$$\n",
    "\n",
    "$$s.t. \\quad y_{i}\\left(w \\cdot x_{i}+b\\right) \\geqslant 1-\\xi_{i}, \\quad i=1,2, \\cdots, N$$\n",
    "\n",
    "$$\\xi_{i} \\geqslant 0, \\quad i=1,2, \\cdots, N$$\n",
    "\n",
    "求解原始最优化问题的解$w^*$和$b^*$，得到线性支持向量机，其分离超平面为\n",
    "\n",
    "$$w^{*} \\cdot x+b^{*}=0$$\n",
    "\n",
    "分类决策函数为\n",
    "\n",
    "$$f(x)=\\operatorname{sign}\\left(w^{*} \\cdot x+b^{*}\\right)$$\n",
    "\n",
    "线性可分支持向量机的解$w^*$唯一但$b^*$不唯一。对偶问题是\n",
    "\n",
    "$$\\min _{\\alpha} \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_{i} \\alpha_{j} y_{i} y_{j}\\left(x_{i} \\cdot x_{j}\\right)-\\sum_{i=1}^{N} \\alpha_{i}$$\n",
    "\n",
    "$$s.t. \\quad \\sum_{i=1}^{N} \\alpha_{i} y_{i}=0$$\n",
    "\n",
    "$$0 \\leqslant \\alpha_{i} \\leqslant C, \\quad i=1,2, \\cdots, N$$\n",
    "\n",
    "线性支持向量机的对偶学习算法，首先求解对偶问题得到最优解$\\alpha^*$，然后求原始问题最优解$w^*$和$b^*$，得出分离超平面和分类决策函数。\n",
    "\n",
    "对偶问题的解$\\alpha^*$中满$\\alpha_{i}^{*}>0$的实例点$x_i$称为支持向量。支持向量可在间隔边界上，也可在间隔边界与分离超平面之间，或者在分离超平面误分一侧。最优分离超平面由支持向量完全决定。\n",
    "\n",
    "线性支持向量机学习等价于最小化二阶范数正则化的合页函数\n",
    "\n",
    "$$\\sum_{i=1}^{N}\\left[1-y_{i}\\left(w \\cdot x_{i}+b\\right)\\right]_{+}+\\lambda\\|w\\|^{2}$$\n",
    "\n",
    "3．非线性支持向量机\n",
    "\n",
    "对于输入空间中的非线性分类问题，可以通过非线性变换将它转化为某个高维特征空间中的线性分类问题，在高维特征空间中学习线性支持向量机。由于在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都只涉及实例与实例之间的内积，所以不需要显式地指定非线性变换，而是用核函数来替换当中的内积。核函数表示，通过一个非线性转换后的两个实例间的内积。具体地，$K(x,z)$是一个核函数，或正定核，意味着存在一个从输入空间x到特征空间的映射$\\mathcal{X} \\rightarrow \\mathcal{H}$，对任意$\\mathcal{X}$，有\n",
    "\n",
    "$$K(x, z)=\\phi(x) \\cdot \\phi(z)$$\n",
    "\n",
    "对称函数$K(x,z)$为正定核的充要条件如下：对任意$$\\mathrm{x}_{\\mathrm{i}} \\in \\mathcal{X}, \\quad \\mathrm{i}=1,2, \\ldots, \\mathrm{m}$$，任意正整数$m$，对称函数$K(x,z)$对应的Gram矩阵是半正定的。\n",
    "\n",
    "所以，在线性支持向量机学习的对偶问题中，用核函数$K(x,z)$替代内积，求解得到的就是非线性支持向量机\n",
    "\n",
    "$$f(x)=\\operatorname{sign}\\left(\\sum_{i=1}^{N} \\alpha_{i}^{*} y_{i} K\\left(x, x_{i}\\right)+b^{*}\\right)$$\n",
    "\n",
    "4．SMO算法\n",
    "\n",
    "SMO算法是支持向量机学习的一种快速算法，其特点是不断地将原二次规划问题分解为只有两个变量的二次规划子问题，并对子问题进行解析求解，直到所有变量满足KKT条件为止。这样通过启发式的方法得到原二次规划问题的最优解。因为子问题有解析解，所以每次计算子问题都很快，虽然计算子问题次数很多，但在总体上还是高效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "分离超平面：$w^Tx+b=0$\n",
    "\n",
    "点到直线距离：$r=\\frac{|w^Tx+b|}{||w||_2}$\n",
    "\n",
    "$||w||_2$为2-范数：$||w||_2=\\sqrt[2]{\\sum^m_{i=1}w_i^2}$\n",
    "\n",
    "直线为超平面，样本可表示为：\n",
    "\n",
    "$w^Tx+b\\ \\geq+1$\n",
    "\n",
    "$w^Tx+b\\ \\leq+1$\n",
    "\n",
    "#### margin：\n",
    "\n",
    "**函数间隔**：$label(w^Tx+b)\\ or\\ y_i(w^Tx+b)$\n",
    "\n",
    "**几何间隔**：$r=\\frac{label(w^Tx+b)}{||w||_2}$，当数据被正确分类时，几何间隔就是点到超平面的距离\n",
    "\n",
    "为了求几何间隔最大，SVM基本问题可以转化为求解:($\\frac{r^*}{||w||}$为几何间隔，(${r^*}$为函数间隔)\n",
    "\n",
    "$$\\max\\ \\frac{r^*}{||w||}$$\n",
    "\n",
    "$$(subject\\ to)\\ y_i({w^T}x_i+{b})\\geq {r^*},\\ i=1,2,..,m$$\n",
    "\n",
    "分类点几何间隔最大，同时被正确分类。但这个方程并非凸函数求解，所以要先①将方程转化为凸函数，②用拉格朗日乘子法和KKT条件求解对偶问题。\n",
    "\n",
    "①转化为凸函数：\n",
    "\n",
    "先令${r^*}=1$，方便计算（参照衡量，不影响评价结果）\n",
    "\n",
    "$$\\max\\ \\frac{1}{||w||}$$\n",
    "\n",
    "$$s.t.\\ y_i({w^T}x_i+{b})\\geq {1},\\ i=1,2,..,m$$\n",
    "\n",
    "再将$\\max\\ \\frac{1}{||w||}$转化成$\\min\\ \\frac{1}{2}||w||^2$求解凸函数，1/2是为了求导之后方便计算。\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ y_i(w^Tx_i+b)\\geq 1,\\ i=1,2,..,m$$\n",
    "\n",
    "②用拉格朗日乘子法和KKT条件求解最优值：\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ -y_i(w^Tx_i+b)+1\\leq 0,\\ i=1,2,..,m$$\n",
    "\n",
    "整合成：\n",
    "\n",
    "$$L(w, b, \\alpha) = \\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$$\n",
    "\n",
    "推导：$\\min\\ f(x)=\\min \\max\\ L(w, b, \\alpha)\\geq \\max \\min\\ L(w, b, \\alpha)$\n",
    "\n",
    "根据KKT条件：\n",
    "\n",
    "$$\\frac{\\partial }{\\partial w}L(w, b, \\alpha)=w-\\sum\\alpha_iy_ix_i=0,\\ w=\\sum\\alpha_iy_ix_i$$\n",
    "\n",
    "$$\\frac{\\partial }{\\partial b}L(w, b, \\alpha)=\\sum\\alpha_iy_i=0$$\n",
    "\n",
    "代入$ L(w, b, \\alpha)$\n",
    "\n",
    "$\\min\\  L(w, b, \\alpha)=\\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^Tw-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i-b\\sum^m_{i=1}\\alpha_iy_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^T\\sum\\alpha_iy_ix_i-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\alpha_iy_iw^Tx_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)$\n",
    "\n",
    "再把max问题转成min问题：\n",
    "\n",
    "$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$\n",
    "\n",
    "$ \\alpha_i \\geq 0,i=1,2,...,m$\n",
    "\n",
    "以上为SVM对偶问题的对偶形式\n",
    "\n",
    "-----\n",
    "#### kernel\n",
    "\n",
    "在低维空间计算获得高维空间的计算结果，也就是说计算结果满足高维（满足高维，才能说明高维下线性可分）。\n",
    "\n",
    "#### soft margin & slack variable\n",
    "\n",
    "引入松弛变量$\\xi\\geq0$，对应数据点允许偏离的functional margin 的量。\n",
    "\n",
    "目标函数：\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2+C\\sum\\xi_i\\qquad s.t.\\ y_i(w^Tx_i+b)\\geq1-\\xi_i$$ \n",
    "\n",
    "对偶问题：\n",
    "\n",
    "$$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$$\n",
    "\n",
    "$$s.t.\\ C\\geq\\alpha_i \\geq 0,i=1,2,...,m\\quad \\sum^m_{i=1}\\alpha_iy_i=0,$$\n",
    "\n",
    "-----\n",
    "\n",
    "#### Sequential Minimal Optimization\n",
    "\n",
    "首先定义特征到结果的输出函数：$u=w^Tx+b$.\n",
    "\n",
    "因为$w=\\sum\\alpha_iy_ix_i$\n",
    "\n",
    "有$u=\\sum y_i\\alpha_iK(x_i, x)-b$\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "$$\\max \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_j<\\phi(x_i)^T,\\phi(x_j)>$$\n",
    "\n",
    "$$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$$\n",
    "\n",
    "$$ \\alpha_i \\geq 0,i=1,2,...,m$$\n",
    "\n",
    "-----\n",
    "参考资料：\n",
    "\n",
    "[1] :[Lagrange Multiplier and KKT](http://blog.csdn.net/xianlingmao/article/details/7919597)\n",
    "\n",
    "[2] :[推导SVM](https://my.oschina.net/dfsj66011/blog/517766)\n",
    "\n",
    "[3] :[机器学习算法实践-支持向量机(SVM)算法原理](http://pytlab.org/2017/08/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/)\n",
    "\n",
    "[4] :[Python实现SVM](http://blog.csdn.net/wds2006sdo/article/details/53156589)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns =iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    data = np.array(df.iloc[:100, [0,1,-1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i, -1] == 0:\n",
    "            data[i, -1] = -1\n",
    "    return data[:, :2], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c11dc17c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, max_iter =100, kernel = 'linear'):\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel = kernel\n",
    "    def init_args(self, features, labels):\n",
    "        self.m, self.n = features.shape\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "        self.b = 0.0\n",
    "        # 将Ei保存在一个列表里\n",
    "        self.alpha = np.ones(self.m)\n",
    "        self.E = [self._E(i) for i in range(self.m)]\n",
    "        # 松弛变量\n",
    "        self.C = 1.0\n",
    "    \n",
    "    def _KKT(self, i):\n",
    "        y_g = self._g(i) * self.Y[i]\n",
    "        if self.alpha[i] == 0:\n",
    "            return y_g >= 1\n",
    "        elif 0 < self.alpha[i] < self.C:\n",
    "            return y_g == 1\n",
    "        else:\n",
    "            return y_g <= 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0716a2a2bd975815f974ac9d1e01ab62d1944d0794eebdec037b5fef9dc00044"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
